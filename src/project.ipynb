{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição de Consumo de Combustível"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação de modelos de aprendizado supervisionado para predizer o consumo de combustível de carros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import preprocessing as pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui foi realizado o carregamento dos dados originais de um arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('data/car_data_original.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após isso, realizou-se a remoção das instâncias de carros elétricos pois continham muitos atributos faltantes e removeu-se os atributos de consumo em rodovia e cidade pois podem ser altamente colineares com a saída, simplificando demais o trabalho do preditor. Depois, separou-se as instâncias de treinamento/validação das instâncias de teste com o código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo os atributos colineares\n",
    "no_colinear_df = pre.drop_atributes(original_df, ['highway_mpg', 'city_mpg'])\n",
    "\n",
    "# Removendo as instâncias com NaN\n",
    "no_nan_df = pre.remove_instances_with_nan(no_colinear_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the variables to be analyzed (X) and predicted (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = original_df.drop(columns=[\"city_mpg\", \"highway_mpg\"])\n",
    "X = df_filtered.drop(columns=[\"combination_mpg\"])\n",
    "y = df_filtered[\"combination_mpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinando o tamanho dos conjuntos de Teste e Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forcing at least one instance of every category to appear in the fossil_fuel dataset.\n",
    "\n",
    "As in no_electric_cars, there isnt any strategy for dealing with non represented instances during the testing phase, we force every instance to appear at least once in the training case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = set()\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "for feature in categorical_features:\n",
    "    unique_values = X[feature].unique()\n",
    "    for value in unique_values:\n",
    "        index = X[X[feature] == value].index[0]\n",
    "        train_indices.add(index)\n",
    "\n",
    "train_indices = list(train_indices)\n",
    "X_train_mandatory = X.loc[train_indices]\n",
    "y_train_mandatory = y.loc[train_indices]\n",
    "\n",
    "X = X.drop(train_indices)\n",
    "y = y.drop(train_indices)\n",
    "        \n",
    "test_size = test_size * (len(X) + len(X_train_mandatory)) / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o conjunto de Teste antes de começar qualquer treinamento ou avaliação de modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
