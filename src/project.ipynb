{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição de Consumo de Combustível"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação de modelos de aprendizado supervisionado para predizer o consumo de combustível de carros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "import preprocessing as pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui foi realizado o carregamento dos dados originais de um arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('data/car_data_original.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após isso, realizou-se a remoção das instâncias de carros elétricos pois continham muitos atributos faltantes e removeu-se os atributos de consumo em rodovia e cidade pois podem ser altamente colineares com a saída, simplificando demais o trabalho do preditor. Depois, separou-se as instâncias de treinamento/validação das instâncias de teste com o código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo os atributos colineares\n",
    "no_colinear_df = pre.drop_atributes(original_df, ['highway_mpg', 'city_mpg'])\n",
    "\n",
    "# Removendo as instâncias com NaN\n",
    "no_nan_df = pre.remove_instances_with_nan(no_colinear_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the variables to be analyzed (X) and predicted (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filtered = original_df.drop(columns=[\"city_mpg\", \"highway_mpg\"])\n",
    "X = no_nan_df.drop(columns=[\"combination_mpg\"])\n",
    "y = no_nan_df[\"combination_mpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinando o tamanho dos conjuntos de Teste e Validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forçando ao menos uma instância de cada categoria apareça no dataset de treino.\n",
    "\n",
    "Forcing at least one instance of every category to appear in the fossil_fuel dataset.\n",
    "\n",
    "As in no_electric_cars, there isnt any strategy for dealing with non represented instances during the testing phase, we force every instance to appear at least once in the training case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = set()\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "for feature in categorical_features:\n",
    "    unique_values = X[feature].unique()\n",
    "    for value in unique_values:\n",
    "        index = X[X[feature] == value].index[0]\n",
    "        train_indices.add(index)\n",
    "\n",
    "train_indices = list(train_indices)\n",
    "X_train_mandatory = X.loc[train_indices]\n",
    "y_train_mandatory = y.loc[train_indices]\n",
    "\n",
    "X = X.drop(train_indices)\n",
    "y = y.drop(train_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão de Dados e Treinamento para primeiras Avaliações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o conjunto de Teste antes de começar qualquer treinamento ou avaliação de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento com KFold e resultados - falta organizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE using the knn method: 18.384057971014492\n",
      "Average MSE using the knn method: 106.03260869565219\n",
      "\n",
      "\n",
      "Average MAE using the random_forest method: 12.557776749103175\n",
      "Average MSE using the random_forest method: 30.94808938735047\n",
      "\n",
      "\n",
      "Average MAE using the linear_regression method: 1.0629426136684348\n",
      "Average MSE using the linear_regression method: 2.292842054181946\n",
      "\n",
      "\n",
      "Average MAE using the neural_networks method: 1.1927060132634846\n",
      "Average MSE using the neural_networks method: 2.2425802766288685\n",
      "\n",
      "\n",
      "Average MAE using the svm method: 12.858357924648157\n",
      "Average MSE using the svm method: 68.80033668376156\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra iterations to calculate average and increase reproducibility\n",
    "n_repeats = 1\n",
    "k = 9 # K for Knn\n",
    "Ksplit = 10\n",
    "plot_flag = False  \n",
    "\n",
    "methods = [\n",
    "    \"knn\",\n",
    "    \"random_forest\",\n",
    "    \"linear_regression\",\n",
    "    \"neural_networks\",\n",
    "    \"svm\",\n",
    "]\n",
    "\n",
    "for method in methods:\n",
    "        mae_total = 0\n",
    "        mse_total = 0\n",
    "        all_predictions = []  # List to store predictions for each split\n",
    "        for split_random_state in range(0, n_repeats):\n",
    "            # Separate validation data and the remaining instances\n",
    "            X_train, X_val, y_train, y_val  = train_test_split(X, y, test_size=val_size, random_state=split_random_state)\n",
    "            # Split the remaining instances in Ksplit parts\n",
    "            kf = KFold(n_splits=Ksplit, shuffle=True, random_state=split_random_state)\n",
    "            for train_index, test_index in kf.split(X_train):\n",
    "                X_train, X_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "                y_train, y_test = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "                # If no_electric_cars, join the forced test_case with the random test_case\n",
    "                # Concatanate the mandatory and training sets\n",
    "                X_train = pd.concat([X_train_mandatory, X_train])\n",
    "                y_train = pd.concat([y_train_mandatory, y_train])\n",
    "\n",
    "                # Preprocessing is sensitive to type\n",
    "                # Separate analyzed features into numerical and categorical\n",
    "                # As to apply preprocessing only to valid features\n",
    "                numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "                categorical_features = X_train.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "                # ColumnTransformer applies preprocessing patterns e.g. StandardScaler() and\n",
    "                # OneHotEncoder() to groups, e.g. numerical_features and categorical_features\n",
    "                # Preprocessor will be applied to every dataset\n",
    "                preprocessor = ColumnTransformer([\n",
    "                    #(\"num\", StandardScaler(), numerical_features),\n",
    "                    #(\"cat\", OneHotEncoder(), categorical_features)\n",
    "                    #(\"num\", PolynomialFeatures(degree=2, include_bias=False), numerical_features),\n",
    "                    (\"num\", StandardScaler(), numerical_features),\n",
    "                    (\"cat\", OneHotEncoder(), categorical_features)\n",
    "                ])\n",
    "                # Select model and configuration for use in the pipeline\n",
    "                match method:\n",
    "                    case \"knn\":\n",
    "                        model = KNeighborsClassifier(n_neighbors=k)\n",
    "                    case \"random_forest\":\n",
    "                        model = RandomForestRegressor(max_depth=6, random_state=split_random_state)\n",
    "                    case \"linear_regression\":\n",
    "                        model = LinearRegression()\n",
    "                    case \"neural_networks\":\n",
    "                        model = MLPRegressor(random_state=split_random_state, max_iter=2500)\n",
    "                    case \"svm\":\n",
    "                        model = SVR(C=1.0, epsilon=0.2)\n",
    "                # Pipeline applies the preprocessed dataset to the model for fitting\n",
    "                pipe = Pipeline([\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"regressor\", model)\n",
    "                ])\n",
    "\n",
    "                # Fitting the pipeline\n",
    "                pipe.fit(X_train, y_train)\n",
    "\n",
    "                # Prediction and evaluation\n",
    "                y_pred = pipe.predict(X_test)\n",
    "                # all_predictions.append(y_pred)\n",
    "\n",
    "                if plot_flag:\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    plt.scatter(y_test, y_pred, color='blue', alpha=0.6, label='Average Predicted vs Actual')\n",
    "                    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Ideal Fit Line')\n",
    "                    plt.xlabel('Actual Combination MPG')\n",
    "                    plt.ylabel('Average Predicted Combination MPG')\n",
    "                    plt.title(f'{method.upper()} Model: Average Predicted vs Actual Combination MPG')\n",
    "                    plt.legend()\n",
    "                    plt.grid(True)\n",
    "                    plt.savefig(f'src/plots/{method}_actual_vs_predicted.png')\n",
    "\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                mae_total += mae\n",
    "                mse_total += mse\n",
    "\n",
    "            #print(\"Mean Absolute Error (MAE) for iteration {} of {} using the {} method:\".format(split_random_state+1, data_case, method), mae)\n",
    "            #print(\"Mean Squared Error (MSE) for iteration {} of {} using the {} method:\".format(split_random_state+1, data_case, method), mse)\n",
    "            #print(\"\\n\")\n",
    "        \n",
    "        #all_predictions = np.array(all_predictions)\n",
    "        #print(\"ALL\")\n",
    "        #print(all_predictions)\n",
    "        #average_predictions = np.mean(all_predictions, axis=0)\n",
    "        #print(\"Avg\")\n",
    "        #print(average_predictions)\n",
    "\n",
    "        mae_med = mae_total/n_repeats\n",
    "        mse_med = mse_total/n_repeats\n",
    "        print(\"Average MAE using the {} method: {}\".format(method, mae_med))\n",
    "        print(\"Average MSE using the {} method: {}\".format( method, mse_med))\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
